{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Introduction to Video Storyboarding with Amazon Nova Reel 1.1\n",
    "\n",
    "Welcome to the third module of the Amazon Nova Reel Workshop! In this hands-on session, we'll explore the powerful video storyboarding capabilities of Amazon Nova Reel 1.1. This enhancement allows you to create videos up to 2 minutes long using either automated or manual storyboarding approaches.\n",
    "\n",
    "## Use Case\n",
    "\n",
    "OctankFashion wants to create more immersive marketing videos for their new summer t-shirt collection featuring palm tree designs. Traditional video production requires extensive planning, storyboarding, multiple shooting locations, and significant post-production work. With Nova Reel 1.1, OctankFashion can:\n",
    "\n",
    "- Create longer form narrative videos that tell the story of how their products are designed, made, and enjoyed\n",
    "- Transform existing product images into components of a larger storytelling video\n",
    "- Reduce time and cost associated with traditional video production\n",
    "\n",
    "## Workshop Objectives\n",
    "\n",
    "By the end of this module, you will:\n",
    "\n",
    "- Understand the difference between automated and manual storyboarding approaches\n",
    "- Learn how to create longer narrative videos up to 2 minutes in length\n",
    "- Experience how to build a video storyboard using both text-only and image-based approaches\n",
    "\n",
    "## Features We'll Use\n",
    "\n",
    "During this workshop module, we'll leverage the following features of Amazon Nova Reel 1.1:\n",
    "\n",
    "- MULTI_SHOT_AUTOMATED: Create longer videos with a single comprehensive prompt\n",
    "- MULTI_SHOT_MANUAL: Design each shot individually for greater creative control\n",
    "- Image-based video generation within a multi-shot storyboard\n",
    "\n",
    "Let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Setting up your environment\n",
    "\n",
    "First, we'll create an instance of the Bedrock Runtime client which we'll use to invoke the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "import base64\n",
    "import video_gen_util\n",
    "from IPython.display import display, Video\n",
    "\n",
    "boto3.setup_default_session(region_name=\"us-east-1\")\n",
    "session = boto3.Session()\n",
    "sts_client = session.client(\"sts\")\n",
    "\n",
    "bedrock_runtime = boto3.client(\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "#### Setting up storage\n",
    "\n",
    "Generating a video takes 1 minute or longer depending on the duration you've selected. To accommodate this execution time, the Bedrock Runtime introduces a new asynchronous invocation API. You start generating a video by calling the `start_async_invoke()` method on the Bedrock Runtime client. When the generation job completes, Bedrock automatically saves the generated video to an S3 bucket you specify.\n",
    "\n",
    "Run the cell below to automatically create a new S3 bucket in your account which we will use as a destination for your videos. (If you already have an existing bucket you'd like to use, edit the `s3_destination_bucket` variable to use that bucket's ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = session.region_name\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "\n",
    "# Replace this with an existing bucket name if you'd like.\n",
    "bucket_name = f\"nova-samples-{region}-{account_id}\"\n",
    "\n",
    "# Create the bucket\n",
    "boto3.client(\"s3\").create_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Example 1: Automated Multi-Shot Video\n",
    "\n",
    "OctankFashion wants to create a promotional video featuring lifestyle imagery reflecting the inspiration for their palm tree t-shirt collection. With Nova Reel 1.1's automated multi-shot feature, they can describe the entire narrative in a single prompt and let the model determine the best way to segment and sequence the shots.\n",
    "\n",
    "The **MULTI_SHOT_AUTOMATED** task type accepts:\n",
    "\n",
    "- A single text prompt up to 4,000 characters\n",
    "- Duration parameter (multiple of 6 seconds, between 12-120 seconds)\n",
    "- No input images are supported in this mode\n",
    "\n",
    "Let's generate a 30-second automated multi-shot video showcasing OctankFashion's palm tree t-shirts:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main input parameters\n",
    "text_prompt = \"A cinematic video that showcases the beauty and calm of a tropical island. Start with a closeup of a shell in the sand near the surf. Transition to handheld shot (shakey) of a simple, welcoming hut at the edge of a jungle of palm trees bordering the sand, slowy approaching the hut's dark entrance. End with a drone shot of the beautiful isolated tropical island the hut is on.\"\n",
    "\n",
    "duration_seconds = 18  # Must be a multiple of 6 in range [12, 120]\n",
    "seed = 1016  # Setting a specific seed for reproducibility\n",
    "\n",
    "model_input = {\n",
    "    \"taskType\": \"MULTI_SHOT_AUTOMATED\",\n",
    "    \"multiShotAutomatedParams\": {\"text\": text_prompt},\n",
    "    \"videoGenerationConfig\": {\n",
    "        \"durationSeconds\": duration_seconds,\n",
    "        \"fps\": 24,  # Must be 24\n",
    "        \"dimension\": \"1280x720\",  # Must be \"1280x720\"\n",
    "        \"seed\": seed,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Start the asynchronous video generation job\n",
    "invocation = bedrock_runtime.start_async_invoke(\n",
    "    modelId=\"amazon.nova-reel-v1:1\",\n",
    "    modelInput=model_input,\n",
    "    outputDataConfig={\"s3OutputDataConfig\": {\"s3Uri\": f\"s3://{bucket_name}\"}},\n",
    ")\n",
    "\n",
    "# Store the invocation ARN for later status checking\n",
    "invocation_arn = invocation[\"invocationArn\"]\n",
    "job_id = invocation_arn.split(\"/\")[-1]\n",
    "s3_location = f\"s3://{bucket_name}/{job_id}\"\n",
    "\n",
    "# Print the response\n",
    "print(\"\\nResponse:\")\n",
    "print(json.dumps(invocation, indent=2, default=str))\n",
    "print(f\"\\nVideo will be available at: {s3_location}/output.mp4 when complete\")\n",
    "\n",
    "# Save invocation details for reference\n",
    "video_gen_util.save_invocation_info(invocation, model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "#### Checking the Status of Your Video Generation\n",
    "\n",
    "The following code will check the current status of the video generation job. Run this code to see how it works, then continue on. (We'll be downloading completed jobs automatically later in this notebook.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock_runtime.get_async_invoke(invocationArn=invocation_arn)\n",
    "status = response[\"status\"]\n",
    "print(f\"Status: {status}\")\n",
    "print(\"\\nFull response:\")\n",
    "print(json.dumps(response, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Example 2: Manual Multi-Shot Video (Text-Only)\n",
    "\n",
    "For greater creative control, OctankFashion can use Nova Reel 1.1's manual storyboarding feature. This allows you to precisely define each shot in your video with its own unique prompt. The **MULTI_SHOT_MANUAL** task type lets you:\n",
    "\n",
    "- Create up to 20 individual shots (each 6 seconds long, resulting in up to 2 minutes of video)\n",
    "- Define each shot with its own text prompt (up to 512 characters)\n",
    "- Optionally include a reference image for any shot\n",
    "\n",
    "Let's create a manual storyboard that tells the story of OctankFashion's palm tree T-shirt from concept to finished product:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define each shot in the storyboard\n",
    "shots = [\n",
    "    {\n",
    "        \"text\": \"Aerial drone shot of a tropical beach with palm trees swaying in the breeze. Golden morning light bathes the scene. Professional, cinematic quality with rich colors.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Close-up of design sketches of palm tree patterns spread on a wooden table, a pencil rolls slowly across the paper. Soft, natural lighting from a nearby window.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Wide shot of a clothing workshop with fabric being cut by machine into white t-shirt patterns. Clean, organized space with muted colors and professional equipment in operation.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Slow motion macro shot of a finished white t-shirt with the palm tree graphic being illuminated by changing light, showing the texture and print quality in detail.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Smooth dolly shot of the finished white palm tree graphic t-shirt displayed on a minimalist mannequin torso against a white background, slowly rotating to show all angles.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# Setting seed for reproducibility\n",
    "seed = 230\n",
    "\n",
    "model_input = {\n",
    "    \"taskType\": \"MULTI_SHOT_MANUAL\",\n",
    "    \"multiShotManualParams\": {\"shots\": shots},\n",
    "    \"videoGenerationConfig\": {\n",
    "        \"fps\": 24,  # Must be 24\n",
    "        \"dimension\": \"1280x720\",  # Must be \"1280x720\"\n",
    "        \"seed\": seed,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Start the asynchronous video generation job\n",
    "invocation = bedrock_runtime.start_async_invoke(\n",
    "    modelId=\"amazon.nova-reel-v1:1\",\n",
    "    modelInput=model_input,\n",
    "    outputDataConfig={\"s3OutputDataConfig\": {\"s3Uri\": f\"s3://{bucket_name}\"}},\n",
    ")\n",
    "\n",
    "# Store the invocation ARN for later status checking\n",
    "invocation_arn_manual = invocation[\"invocationArn\"]\n",
    "job_id = invocation_arn_manual.split(\"/\")[-1]\n",
    "s3_location = f\"s3://{bucket_name}/{job_id}\"\n",
    "\n",
    "# Print the response\n",
    "print(\"\\nResponse:\")\n",
    "print(json.dumps(invocation, indent=2, default=str))\n",
    "print(f\"\\nVideo will be available at: {s3_location}/output.mp4 when complete\")\n",
    "\n",
    "# Save invocation details for reference\n",
    "video_gen_util.save_invocation_info(invocation, model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Example 3: Manual Multi-Shot Video with Images\n",
    "\n",
    "For the most precise control, OctankFashion can use their actual product images as the foundation for specific shots in their promotional video. This approach is ideal when you want to ensure brand consistency and product accuracy in the final video.\n",
    "\n",
    "The image-based approach allows you to:\n",
    "\n",
    "- Provide a reference image for any or all shots in your storyboard\n",
    "- Add camera movement and life to static product photos\n",
    "- Maintain perfect product representation while adding motion and context\n",
    "\n",
    "Here are the images we'll be using:\n",
    "\n",
    "<div style=\"display: flex; max-width:100%; gap:10px\">\n",
    "  <div style=\"flex: 1; display: flex; flex-direction: column; align-items: center\">\n",
    "    <img src=\"data/ref_img_1.png\">\n",
    "  </div>\n",
    "  <div style=\"flex: 1; display: flex; flex-direction: column; align-items: center\">\n",
    "    <img src=\"data/ref_img_2.png\">\n",
    "  </div>\n",
    "  <div style=\"flex: 1; display: flex; flex-direction: column; align-items: center\">\n",
    "    <img src=\"data/ref_img_3.png\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "Let's create a function to help us convert images to base64 format:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_base64(image_path: str):\n",
    "    \"\"\"\n",
    "    Helper function which converts an image file to a base64 encoded string.\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read())\n",
    "        return encoded_string.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Now, let's create a storyboard using OctankFashion's actual product images:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define shots using both text and images\n",
    "shots = [\n",
    "    {\n",
    "        \"text\": \"Slow tracking shot moving across the retail display, focusing on the palm tree t-shirt. Static clothing display with soft store lighting. Camera gradually moves from left to right, revealing more of the store environment in the background.\",\n",
    "        \"image\": {\n",
    "            \"format\": \"png\",\n",
    "            \"source\": {\"bytes\": image_to_base64(\"data/ref_img_1.png\")},\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Gentle breeze moves palm tree branches and rustles the t-shirt fabric. Waves roll in the distance, beach sand shifts slightly with the wind. Natural tropical sunlight creates perfect lighting on the shirt design.\",\n",
    "        \"image\": {\n",
    "            \"format\": \"png\",\n",
    "            \"source\": {\"bytes\": image_to_base64(\"data/ref_img_2.png\")},\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Slow dolly back shot revealing the entire poolside scene. Water ripples gently in the pool, reflective light plays across the t-shirt fabric. A tranquil resort atmosphere with subtle ambient movement.\",\n",
    "        \"image\": {\n",
    "            \"format\": \"png\",\n",
    "            \"source\": {\"bytes\": image_to_base64(\"data/ref_img_3.png\")},\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "# Setting seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "model_input = {\n",
    "    \"taskType\": \"MULTI_SHOT_MANUAL\",\n",
    "    \"multiShotManualParams\": {\"shots\": shots},\n",
    "    \"videoGenerationConfig\": {\n",
    "        \"fps\": 24,  # Must be 24\n",
    "        \"dimension\": \"1280x720\",  # Must be \"1280x720\"\n",
    "        \"seed\": seed,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Start the asynchronous video generation job\n",
    "invocation = bedrock_runtime.start_async_invoke(\n",
    "    modelId=\"amazon.nova-reel-v1:1\",\n",
    "    modelInput=model_input,\n",
    "    outputDataConfig={\"s3OutputDataConfig\": {\"s3Uri\": f\"s3://{bucket_name}\"}},\n",
    ")\n",
    "\n",
    "# Store the invocation ARN for later status checking\n",
    "invocation_arn_image = invocation[\"invocationArn\"]\n",
    "job_id = invocation_arn_image.split(\"/\")[-1]\n",
    "s3_location = f\"s3://{bucket_name}/{job_id}\"\n",
    "\n",
    "# Print the response\n",
    "print(\"\\nResponse:\")\n",
    "print(json.dumps(invocation, indent=2, default=str))\n",
    "print(f\"\\nVideo will be available at: {s3_location}/output.mp4 when complete\")\n",
    "\n",
    "# Save invocation details for reference\n",
    "video_gen_util.save_invocation_info(invocation, model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "##### Download and view the generated videos\n",
    "\n",
    "We've provided a set of utility functions in the `video_gen_util.py` script. One of these functions provides one solution to automatically downloading previously completed jobs and monitoring in-progress jobs. Finished jobs will be automatically downloaded to the \"output\" folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# Download and monitor videos from the past N hours\n",
    "duration_hours = 2\n",
    "\n",
    "from_submit_time = datetime.now(timezone.utc) - timedelta(hours=duration_hours)\n",
    "\n",
    "local_file_paths = video_gen_util.monitor_and_download_videos(\"output\", submit_time_after=from_submit_time)\n",
    "\n",
    "for video in local_file_paths:\n",
    "    display(Video(video, embed=True, html_attributes=\"controls loop autoplay\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Additional Options: Using S3 Images\n",
    "\n",
    "For larger productions, OctankFashion might want to store their image assets in S3 directly. Nova Reel 1.1 also supports referencing S3 images in your shot definitions. Instead of providing base64 encoded images, you can reference S3 locations:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "##### Example structure for S3 image reference (not run in this notebook)\n",
    "\n",
    "```python\n",
    "\"image\": {\n",
    "    \"format\": \"png\",  # Must be \"png\" or \"jpeg\"\n",
    "    \"source\": {\n",
    "        \"s3Location\": {\n",
    "            \"uri\": \"s3://your-bucket-name/path/to/image.png\",\n",
    "            \"bucketOwner\": \"optional-bucket-owner-id\"\n",
    "        }\n",
    "    },\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "This approach is particularly useful when building automated workflows or when working with a large image library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Take Away\n",
    "\n",
    "Amazon Nova Reel 1.1's storyboarding features give OctankFashion unprecedented control over their marketing videos. By combining automated multi-shot generation, manual storyboarding, and image-based video creation, they can create compelling narrative videos that showcase their products from concept to customer.\n",
    "\n",
    "In this workshop, you've learned how to generate long-form video content for fashion marketing using both automated and manual storyboarding approaches. With these techniques, OctankFashion can dramatically expand their video marketing capabilities while reducing production time and costs.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
