<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Nova S2S Voice Chatbot</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 10px; }
        #chat-container { width: 100%; padding: 10px; }
        #chat-area { display: block; width: 60%; float: left; height: 640px; overflow-y: auto; padding: 10px; border: 1px solid #f5f4f4; border-radius: 5px; background-color: #f5f4f4;}
        .message-item { position: relative; width: 100%; padding: 10px; overflow: hidden; }
        .message-item .user-message { display: block; float: right; text-align: right; background-color: #2196F3; width: 200px; border-radius: 5px; padding: 10px; color: white;}
        .message-item .bot-message { display: block; float: left; text-align: left; background-color: #4CAF50; width: 200px; border-radius: 5px; padding: 10px; color: white;}
        #events-area { width: 35%; display: block; float: right; }
        .event-section { display: block; position: relative; width: 100%; height: 600px; background-color: #f5f4f4; overflow-y: auto; }
        .event-in { border-radius: 5px; background-color: #4CAF50; color: white; width: 200px; margin: 5px; padding: 5px; }
        .event-out { border-radius: 5px; background-color: #277aee; color: white; width: 200px; margin: 5px; padding: 5px; cursor: pointer; }
        .event-out:hover .details, .event-in:hover .details { display: block; }
        .details { display: none; position: absolute; top: 0; left: 100%; margin-left: 10px; background-color: #f0f0f0; padding: 10px; border: 1px solid #ccc; width: 200px; }
        button { padding: 10px; margin-top: 10px; cursor: pointer; background-color: #007BFF; color: white; border: none; border-radius: 5px; }
        #start-session-btn { display: block; background-color: #28a745; margin-bottom: 10px; }
        #stop-session-btn { display: block; background-color: #dc3545; margin-bottom: 10px; }
        #error { background-color: #f44336; color: white; padding: 10px; text-align: center; font-size: 16px; font-weight: bold; position: fixed; top: 0; left: 0; right: 0; z-index: 1000; display: none; }
    </style>
</head>
<body>
<div id="error"></div>
<div id="chat-container">
    <div>
        <button id="start-session-btn">Start session</button>
        <button id="stop-session-btn" style="display: none;">Stop session</button>
        <br/>
        <div id="chat-area">
        </div>
    </div>
    <div id="events-area">
        <h3>Events</h3>
        <div class="event-section" id="outgoing-events">
        </div>
    </div>

</div>

<script>
    class S2sEvent {
    static DEFAULT_INFER_CONFIG = {
      maxTokens: 1024,
      topP: 0.95,
      temperature: 0.7
    };
  
    static DEFAULT_SYSTEM_PROMPT = "You are a friend. The user and you will engage in a spoken dialog exchanging the transcripts of a natural real-time conversation. Keep your responses short, generally two or three sentences for chatty scenarios.";
  
    static DEFAULT_AUDIO_INPUT_CONFIG = {
      mediaType: "audio/lpcm",
      sampleRateHertz: 16000,
      sampleSizeBits: 16,
      channelCount: 1,
      audioType: "SPEECH",
      encoding: "base64"
    };
  
    static DEFAULT_AUDIO_OUTPUT_CONFIG = {
      mediaType: "audio/lpcm",
      sampleRateHertz: 24000,
      sampleSizeBits: 16,
      channelCount: 1,
      voiceId: "matthew",
      encoding: "base64",
      audioType: "SPEECH"
    };
  
    static DEFAULT_TOOL_CONFIG = {
      tools: [{
        toolSpec: {
          name: "getDateTool",
          description: "get information about the current day",
          inputSchema: {
            json: JSON.stringify({
              "$schema": "http://json-schema.org/draft-07/schema#",
              type: "object",
              properties: {},
              required: []
            })
          }
        }
      },
      {
        toolSpec: {
          name: "getKbTool",
          description: "get information about the Amazon policy",
          inputSchema: {
            json: JSON.stringify({
              "$schema": "http://json-schema.org/draft-07/schema#",
              type: "object",
              properties: {
                query: {
                  type: "string",
                  description: "the query to search"
                }
              },
              required: []
            })
          }
        }
      },
      {
        toolSpec: {
          name: "getTravelPolicyTool",
          description: "get information about the travel with pet policy",
          inputSchema: {
            json: JSON.stringify({
              "$schema": "http://json-schema.org/draft-07/schema#",
              type: "object",
              properties: {
                query: {
                  type: "string",
                  description: "the query to search"
                }
              },
              required: []
            })
          }
        }
      }
    ]
    };
  
    static BYOLLM_TOOL_CONFIG = {
      tools: [{
        toolSpec: {
          name: "lookup",
          description: "Runs query against a knowledge base to retrieve information.",
          inputSchema: {
            json: JSON.stringify({
              "$schema": "http://json-schema.org/draft-07/schema#",
              type: "object",
              properties: {
                query: {
                  type: "string",
                  description: "the query to search"
                }
              },
              required: ["query"]
            })
          }
        }
      }]
    };
  
    static sessionStart(inferenceConfig = S2sEvent.DEFAULT_INFER_CONFIG) {
      return { event: { sessionStart: { inferenceConfiguration: inferenceConfig } } };
    }
  
    static promptStart(promptName, audioOutputConfig = S2sEvent.DEFAULT_AUDIO_OUTPUT_CONFIG, toolConfig = S2sEvent.DEFAULT_TOOL_CONFIG) {
      return {
        event: {
          promptStart: {
            promptName,
            textOutputConfiguration: { mediaType: "text/plain" },
            audioOutputConfiguration: audioOutputConfig,
            toolUseOutputConfiguration: { mediaType: "application/json" },
            toolConfiguration: toolConfig
          }
        }
      };
    }
  
    static contentStartText(promptName, contentName) {
      return {
        event: {
          contentStart: {
            promptName,
            contentName,
            type: "TEXT",
            interactive: true,
            textInputConfiguration: { mediaType: "text/plain" }
          }
        }
      };
    }
  
    static textInput(promptName, contentName, systemPrompt = S2sEvent.DEFAULT_SYSTEM_PROMPT) {
      return {
        event: {
          textInput: {
            promptName,
            contentName,
            content: systemPrompt,
            role: "SYSTEM"
          }
        }
      };
    }
  
    static contentEnd(promptName, contentName) {
      return {
        event: {
          contentEnd: {
            promptName,
            contentName
          }
        }
      };
    }
  
    static contentStartAudio(promptName, contentName, audioInputConfig = S2sEvent.DEFAULT_AUDIO_INPUT_CONFIG) {
      return {
        event: {
          contentStart: {
            promptName,
            contentName,
            type: "AUDIO",
            interactive: true,
            audioInputConfiguration: audioInputConfig
          }
        }
      };
    }
  
    static audioInput(promptName, contentName, content) {
      return {
        event: {
          audioInput: {
            promptName,
            contentName,
            content,
            role: "USER"
          }
        }
      };
    }
  
    static contentStartTool(promptName, contentName, toolUseId) {
      return {
        event: {
          contentStart: {
            promptName,
            contentName,
            interactive: false,
            type: "TOOL",
            toolResultInputConfiguration: {
              toolUseId,
              type: "TEXT",
              textInputConfiguration: { mediaType: "text/plain" }
            }
          }
        }
      };
    }
  
    static textInputTool(promptName, contentName, content) {
      return {
        event: {
          textInput: {
            promptName,
            contentName,
            content,
            role: "TOOL"
          }
        }
      };
    }
  
    static promptEnd(promptName) {
      return {
        event: {
          promptEnd: {
            promptName
          }
        }
      };
    }
  
    static sessionEnd() {
      return { event: { sessionEnd: {} } };
    }
  }
    
</script>
<script>
    // WebSocket connection setup
    //const wsUrl = 'ws://NovaS2-apigw-IwgwFgdCKov1-246264705.us-east-1.elb.amazonaws.com';
    const wsUrl = 'ws://localhost:8081'; // Replace with your WebSocket URL
    const wsManager = new WebSocket(wsUrl);

    wsManager.onopen = () => {
        console.log('WebSocket connection established');
    };

    wsManager.onmessage = (event) => {
        const message = JSON.parse(event.data);
        handleIncomingMessage(message);
    };

    wsManager.onerror = (error) => {
        console.log('WebSocket error:', error);
        setError(`Failed to connect to websocket ${wsUrl}`)
        return;
    };

    wsManager.onclose = () => {
        console.log('WebSocket connection closed');
    };
    
    // UI elements
    const chatArea = document.getElementById('chat-area');
    const ongoingEvents = document.getElementById('outgoing-events');
    const startSessionBtn = document.getElementById('start-session-btn');
    const stopSessionBtn = document.getElementById('stop-session-btn');

    let promptName = null;
    let textContentName = null;
    let audioContentName = null;

    let mediaRecorder;
    let audioChunks = [];
    let isRecording = false;

    // Helper function to display chat message
    function displayChatMessage(message, sender) {
        const messageDiv = document.createElement('div');
        messageDiv.className = sender === 'USER' ? 'user-message' : 'bot-message';
        messageDiv.textContent = message;

        const messageItem = document.createElement('div');
        messageItem.className = "message-item";
        messageItem.appendChild(messageDiv);

        chatArea.appendChild(messageItem);
        chatArea.scrollTop = chatArea.scrollHeight;
    }

    function setError(message) {
        const errorContainer =  document.getElementById('error');
        errorContainer.textContent = message;
        errorContainer.style.display = message === null? "none":"inline";
    }

    let eventsByContentName = {};
    // Group events by content name for display
    function displayEvent(event, type="in") {
        if (event && event.event) {
            const eventName = Object.keys(event?.event)[0];
            let key = null;
            if (eventName === "audioOutput") {
                const contentId = event.event[eventName].contentId;
                key = `${eventName}-${contentId.substr(0,8)}`;
            }
            else if (eventName === "audioInput") {
                const contentName = event.event[eventName].contentName;
                key = `${eventName}-${contentName.substr(0,8)}`;
            }
            else if (eventName === "contentStart") {
                const contentType = event.event[eventName].type;
                key = `${eventName}-${contentType}-${Date.now()}`;
            }
            else {
                key = `${eventName}-${Date.now()}`;
            }

            if (!(key in eventsByContentName)) {
                eventsByContentName[key] = {
                    "type":type, 
                    "name": eventName,
                    "events":[]
                }
            }
            eventsByContentName[key]["events"].push(event);

            ongoingEvents.innerHTML = "";
            for (let key in eventsByContentName) {
                const content = eventsByContentName[key];
                const eventDiv = document.createElement('div');
                eventDiv.className = content.type === "in"?"event-in":"event-out";
                eventDiv.textContent = content["events"].length > 1?`${content.name} (${content["events"].length})`:content.name;
                eventDiv.addEventListener('click', async () => {
                    let jsonStr = "";
                    content["events"].forEach((event)=>{
                        jsonStr += JSON.stringify(event, null, 2) +"\n\n"; 
                    })
                    alert(jsonStr);
                });

                ongoingEvents.prepend(eventDiv);
            }
            
        }
    }

    // Function to send outgoing event
    function sendOutgoingEvent(event) {
        if (wsManager.readyState === WebSocket.OPEN) {
            wsManager.send(JSON.stringify(event));
            displayEvent(event, "out");
        }
    }

    function playBase64LPCM(base64String) {
        // Decode Base64 string to raw LPCM bytes
        const byteCharacters = atob(base64String);
        const byteArrays = new Uint8Array(byteCharacters.length);
        
        for (let i = 0; i < byteCharacters.length; i++) {
            byteArrays[i] = byteCharacters.charCodeAt(i);
        }

        // Construct WAV header (similar to your Python function)
        const sampleRate = 24000; // 24kHz
        const numChannels = 1; // Mono
        const bitsPerSample = 16;
        const byteRate = sampleRate * numChannels * (bitsPerSample / 8);
        const blockAlign = numChannels * (bitsPerSample / 8);
        const wavSize = byteArrays.length + 36;
        
        // Create the WAV header
        const wavHeader = new Uint8Array(44);
        const view = new DataView(wavHeader.buffer);

        // RIFF header
        let offset = 0;
        for (let i = 0; i < 4; i++) view.setUint8(offset++, "RIFF".charCodeAt(i));
        view.setUint32(offset, wavSize, true); offset += 4;
        for (let i = 0; i < 4; i++) view.setUint8(offset++, "WAVE".charCodeAt(i));

        // fmt chunk
        for (let i = 0; i < 4; i++) view.setUint8(offset++, "fmt ".charCodeAt(i));
        view.setUint32(offset, 16, true); offset += 4; // Subchunk1Size (16 for PCM)
        view.setUint16(offset, 1, true); offset += 2;  // AudioFormat (1 for PCM)
        view.setUint16(offset, numChannels, true); offset += 2;  // NumChannels
        view.setUint32(offset, sampleRate, true); offset += 4;  // SampleRate
        view.setUint32(offset, byteRate, true); offset += 4;  // ByteRate
        view.setUint16(offset, blockAlign, true); offset += 2;  // BlockAlign
        view.setUint16(offset, bitsPerSample, true); offset += 2;  // BitsPerSample

        // data chunk
        for (let i = 0; i < 4; i++) view.setUint8(offset++, "data".charCodeAt(i));
        view.setUint32(offset, byteArrays.length, true); offset += 4;

        // Combine WAV header and raw audio data
        const wavBlob = new Blob([wavHeader, byteArrays], { type: "audio/wav" });
        const audioUrl = URL.createObjectURL(wavBlob);

        return audioUrl;
    }


    // Function to handle incoming message and display response
    let audioResponse = {};
    let audioQueue = [];
    function handleIncomingMessage(message) {
        const eventType = Object.keys(message?.event)[0];
        let contentId = null;
        let content = null;
        let contentType = null;
        
        switch(eventType) {
            case "textOutput": 
                const prefix = "Speculative: ";
                const role = message.event[eventType]["role"];
                content = message.event[eventType]["content"];
                if (content.startsWith(prefix) || role === "USER"){
                    content = content.startsWith(prefix) ? content.slice(prefix.length) : content;
                    displayChatMessage(content, message.event[eventType]["role"]);
                }

                break;
            case "audioOutput":
                contentId = message.event[eventType].contentId;
                audioResponse[contentId] += message.event[eventType].content;
                break;
            case "contentStart":
                contentType = message.event[eventType].type;
                contentId = message.event[eventType].contentId;
                if (contentType === "AUDIO") {
                    audioResponse[contentId] = "";
                }
                break;
            case "contentEnd":
                contentType = message.event[eventType].type;
                contentId = message.event[eventType].contentId;
                if (contentType === "AUDIO") {
                    audioUrl = playBase64LPCM(audioResponse[contentId]);
                    // Play audio
                    audioQueue.push(audioUrl);
                    const audio = new Audio(audioUrl);
                    audio.play();

                }

        }

        displayEvent(message, "in");
    }

    // Event handler for starting the microphone
    startSessionBtn.addEventListener('click', async () => {
        try {
            promptName = crypto.randomUUID();
            textContentName = crypto.randomUUID();
            audioContentName = crypto.randomUUID();

            if (wsManager.readyState !== WebSocket.OPEN) {
               wsManager = new WebSocket(wsUrl);
               setTimeout(() => {
                    console.log("After 2 seconds");
                }, 2000); 
            }

            // Start session events
            sendOutgoingEvent(S2sEvent.sessionStart());
            sendOutgoingEvent(S2sEvent.promptStart(promptName));
            sendOutgoingEvent(S2sEvent.contentStartText(promptName, textContentName));
            sendOutgoingEvent(S2sEvent.textInput(promptName, textContentName));
            sendOutgoingEvent(S2sEvent.contentEnd(promptName, textContentName));
            sendOutgoingEvent(S2sEvent.contentStartAudio(promptName, audioContentName));

            const stream = await navigator.mediaDevices.getUserMedia({
            audio: {
                    channelCount: 1,           // Mono
                    sampleRate: 16000,         // 16kHz
                    sampleSize: 16,            // 16-bit
                    echoCancellation: true,    // Enable echo cancellation
                    noiseSuppression: true,    // Enable noise suppression
                    autoGainControl: true      // Enable automatic gain control
                }
            });

            // Create AudioContext for processing
            const audioContext = new AudioContext({
                sampleRate: 16000,
                latencyHint: 'interactive'
            });

            // Create MediaStreamSource
            const source = audioContext.createMediaStreamSource(stream);

            // Create ScriptProcessor for raw PCM data
            const processor = audioContext.createScriptProcessor(512, 1, 1);

            source.connect(processor);
            processor.connect(audioContext.destination);

            processor.onaudioprocess = (e) => {
                const inputData = e.inputBuffer.getChannelData(0);

                const buffer = new ArrayBuffer(inputData.length * 2);
                const pcmData = new DataView(buffer);
                for (let i = 0; i < inputData.length; i++) {
                    const int16 = Math.max(-32768, Math.min(32767, Math.round(inputData[i] * 32767)));
                    pcmData.setInt16(i * 2, int16, true);
                }
                // Binary data string
                let data = "";
                for (let i = 0; i < pcmData.byteLength; i++) {
                    data += String.fromCharCode(pcmData.getUint8(i));
                }

                // Send to WebSocket
                const event = S2sEvent.audioInput(promptName, audioContentName, btoa(data));
                sendOutgoingEvent(event);
            };

            // Store cleanup functions
            window.audioCleanup = () => {
                processor.disconnect();
                source.disconnect();
                stream.getTracks().forEach(track => track.stop());
            };

            mediaRecorder = new MediaRecorder(stream);
            mediaRecorder.ondataavailable = (event) => {
                audioChunks.push(event.data);
            };
            mediaRecorder.onstop = () => {
                const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                const audioUrl = URL.createObjectURL(audioBlob);
                audioChunks = [];

                // Send audio data over WebSocket
                const event = {
                    type: 'audio',
                    payload: {
                        audioUrl: audioUrl
                    }
                };
                sendOutgoingEvent(event);
            };

            mediaRecorder.start();
            isRecording = true;
            startSessionBtn.style.display = 'none';
            stopSessionBtn.style.display = 'inline-block';
            console.log('Microphone recording started');
        } catch (error) {
            console.error('Error accessing microphone: ', error);
        }
    });

    // Event handler for stopping the microphone
    stopSessionBtn.addEventListener('click', () => {
        setError(null);
        if (mediaRecorder && isRecording) {
            mediaRecorder.stop();
            isRecording = false;
            startSessionBtn.style.display = 'inline-block';
            stopSessionBtn.style.display = 'none';
            console.log('Microphone recording stopped');
        }
        wsManager.close();
        sendOutgoingEvent(S2sEvent.contentEnd(promptName, audioContentName));
        sendOutgoingEvent(S2sEvent.promptEnd(promptName));
        sendOutgoingEvent(S2sEvent.sessionEnd());
    });
</script>

</body>
</html>